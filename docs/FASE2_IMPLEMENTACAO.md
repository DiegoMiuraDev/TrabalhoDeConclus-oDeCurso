# üéâ Fase 2: Treinamento do Modelo - IMPLEMENTADA

## ‚úÖ Status: PRONTA PARA EXECU√á√ÉO

A Fase 2 do projeto est√° completamente implementada e pronta para ser executada!

## üì¶ Componentes Implementados

### 1. M√≥dulos Criados

#### `src/models/mobilenet_model.py` ‚úÖ
- **Classe `MobileNetLibrasModel`**: Gerencia o modelo MobileNetV2
- **Fun√ß√µes principais**:
  - `build_model()`: Constr√≥i modelo com Transfer Learning
  - `compile_model()`: Compila com otimizador e m√©tricas
  - `unfreeze_base_layers()`: Para fine-tuning
  - `predict()`: Faz predi√ß√µes
  - `save_model()` / `load_model()`: Salva/carrega modelo
- **Fun√ß√£o helper**: `create_mobilenet_model()` para cria√ß√£o r√°pida

#### `src/models/training.py` ‚úÖ
- **Classe `LibrasModelTrainer`**: Gerencia o treinamento
- **Callback personalizado**: `TrainingMetricsLogger` para m√©tricas
- **Fun√ß√µes principais**:
  - `setup_callbacks()`: Configura EarlyStopping, ReduceLR, etc
  - `train()`: Treina o modelo com/sem data augmentation
  - `evaluate()`: Avalia modelo
  - `get_training_summary()`: Resumo do treinamento
  - `save_history()`: Salva hist√≥rico
- **Fun√ß√£o helper**: `train_libras_model()` para treinamento r√°pido

### 2. Notebooks

#### `notebooks/02_model_training.ipynb` ‚úÖ
Notebook interativo com c√©lulas para:
- Importa√ß√£o de bibliotecas
- Verifica√ß√£o do sistema (GPU)
- Carregamento dos dados
- Pr√©-processamento
- Cria√ß√£o do modelo
- Treinamento
- Avalia√ß√£o
- Visualiza√ß√µes
- Salvamento de resultados

### 3. Scripts

#### `scripts/train_model.py` ‚úÖ
Script completo e autom√°tico que:
- Carrega dataset do Kaggle
- Pr√©-processa imagens
- Cria modelo MobileNetV2
- Treina com callbacks
- Avalia em treino/valida√ß√£o/teste
- Gera visualiza√ß√µes
- Salva modelo e m√©tricas

### 4. Documenta√ß√£o

#### `docs/FASE2_GUIA.md` ‚úÖ
Guia completo com:
- Instru√ß√µes de execu√ß√£o
- Configura√ß√µes principais
- Troubleshooting
- Melhores pr√°ticas
- Checklist de conclus√£o

## üöÄ Como Executar

### Op√ß√£o 1: Notebook (Interativo)

```bash
# Local
jupyter notebook notebooks/02_model_training.ipynb

# Google Colab
# 1. Upload do notebook para o Colab
# 2. Ativar GPU: Runtime ‚Üí Change runtime type ‚Üí GPU
# 3. Executar c√©lulas sequencialmente
```

### Op√ß√£o 2: Script (Autom√°tico)

```bash
cd /root/tcc
python scripts/train_model.py
```

## üìä Arquitetura do Modelo

```
Input (224, 224, 3)
         ‚Üì
MobileNetV2 Base (ImageNet)
    [Congelado]
         ‚Üì
   Global Average Pooling
         ‚Üì
     Dense(128, ReLU)
         ‚Üì
     Dropout(0.5)
         ‚Üì
     Dense(64, ReLU)
         ‚Üì
     Dropout(0.25)
         ‚Üì
   Dense(24, Softmax)
         ‚Üì
   Output (24 classes)
```

## ‚öôÔ∏è Configura√ß√µes Padr√£o

### Dataset
- **Classes**: 24 letras de Libras
- **Tamanho**: 224x224 RGB
- **Divis√£o**: 70% treino, 10% valida√ß√£o, 20% teste

### Modelo
- **Base**: MobileNetV2 (pr√©-treinado ImageNet)
- **Dropout**: 0.5
- **Dense Units**: 128

### Treinamento
- **√âpocas**: 50 (com early stopping)
- **Batch Size**: 32
- **Learning Rate**: 0.001
- **Optimizer**: Adam
- **Loss**: Categorical Crossentropy

## üìà M√©tricas Calculadas

1. **Acur√°cia** (Treino, Valida√ß√£o, Teste)
2. **Perda** (Treino, Valida√ß√£o, Teste)
3. **Matriz de Confus√£o**
4. **Acur√°cia por Classe**
5. **Precision, Recall, F1-Score** por classe

## üé® Visualiza√ß√µes Geradas

1. **Training History**: Gr√°ficos de acur√°cia e perda ao longo das √©pocas
2. **Confusion Matrix**: Matriz de confus√£o normalizada
3. **Class Accuracy**: Acur√°cia individual de cada letra
4. **Prediction Samples**: Amostras com predi√ß√µes (corretas/incorretas)

## üìÅ Estrutura de Sa√≠da

```
tcc/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ libras_mobilenetv2.h5          # Modelo treinado (~14MB)
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ training_history.npy           # Hist√≥rico numpy
‚îÇ   ‚îú‚îÄ‚îÄ metrics.npy                    # M√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.npy           # CM numpy
‚îÇ   ‚îú‚îÄ‚îÄ classification_report.npy      # Relat√≥rio
‚îÇ   ‚îú‚îÄ‚îÄ training_history.png           # üìä Gr√°fico
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png           # üìä Gr√°fico
‚îÇ   ‚îú‚îÄ‚îÄ class_accuracy.png             # üìä Gr√°fico
‚îÇ   ‚îî‚îÄ‚îÄ prediction_samples.png         # üìä Gr√°fico
‚îî‚îÄ‚îÄ logs/
    ‚îî‚îÄ‚îÄ tensorboard/                   # Logs TB
```

## üéØ Resultados Esperados

### Performance Target
- **Acur√°cia de Teste**: >85%
- **Converg√™ncia**: 20-30 √©pocas
- **Tempo de Treinamento**: 
  - Com GPU: 30-45 minutos
  - Sem GPU: 2-3 horas

### Indicadores de Qualidade
- ‚úÖ Diferen√ßa treino-valida√ß√£o <10% (pouco overfitting)
- ‚úÖ Maioria das classes >80% acur√°cia
- ‚úÖ Diagonal forte na matriz de confus√£o
- ‚úÖ F1-Score m√©dio >0.85

## üîß Funcionalidades Extras

### Data Augmentation
```python
# Ativar no treinamento
trainer.train(
    ...,
    use_data_augmentation=True  # Rota√ß√£o, zoom, shift
)
```

### Fine-Tuning
```python
# Descongelar √∫ltimas 30 camadas do MobileNetV2
model_builder.unfreeze_base_layers(n_layers=30)
model_builder.compile_model(learning_rate=0.0001)  # LR menor
```

### TensorBoard
```python
# Logs em tempo real
trainer.setup_callbacks(
    tensorboard_log_dir="logs/tensorboard"
)

# Visualizar no terminal
# tensorboard --logdir=logs/tensorboard
```

## üÜò Troubleshooting Comum

### Erro: "FileNotFoundError: CSV n√£o encontrado"
**Solu√ß√£o**: Execute a Fase 1 primeiro ou baixe o dataset do Kaggle

### Erro: "Out of Memory"
**Solu√ß√£o**: Reduza `batch_size` de 32 para 16 ou 8

### Aviso: "No GPU found"
**Solu√ß√£o**: Use Google Colab ou treine com CPU (mais lento)

### Problema: Acur√°cia estagnada
**Solu√ß√£o**: 
1. Ative data augmentation
2. Ajuste learning rate
3. Tente fine-tuning

## üí° Dicas de Otimiza√ß√£o

### Para Melhor Performance
1. **Use GPU**: Colab gratuito ou local com CUDA
2. **Data Augmentation**: Aumenta generaliza√ß√£o
3. **Fine-tuning**: Ap√≥s converg√™ncia inicial
4. **Ensemble**: Combine m√∫ltiplos modelos

### Para Experimenta√ß√£o
1. **Teste diferentes LRs**: 0.01, 0.001, 0.0001
2. **Varie dropout**: 0.3, 0.5, 0.7
3. **Mude arquitetura**: EfficientNet, ResNet
4. **Ajuste dense units**: 64, 128, 256

## üìö Depend√™ncias

Todas as depend√™ncias est√£o em `requirements.txt`:
```txt
tensorflow>=2.10.0
keras>=2.10.0
opencv-python>=4.5.0
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.5.0
seaborn>=0.11.0
scikit-learn>=1.0.0
```

## ‚ú® Pr√≥ximos Passos

### Ap√≥s Treinamento Bem-Sucedido

1. **Analisar Resultados**: Revisar m√©tricas e gr√°ficos
2. **Identificar Melhorias**: Classes com baixa acur√°cia
3. **Otimizar (se necess√°rio)**: Fine-tuning, data augmentation
4. **Prosseguir para Fase 3**: Aplica√ß√£o em tempo real!

### Se Resultados Insatisfat√≥rios

1. **Revisar dados**: Qualidade e distribui√ß√£o
2. **Ajustar hiperpar√¢metros**: LR, dropout, √©pocas
3. **Aumentar dados**: Mais samples ou augmentation
4. **Mudar arquitetura**: Testar outros modelos

## üéì Conceitos Aplicados

### Transfer Learning
- Aproveita conhecimento do ImageNet
- Reduz tempo de treinamento
- Melhora generaliza√ß√£o

### MobileNetV2
- Arquitetura leve e eficiente
- Inverted Residuals
- Linear Bottlenecks
- Ideal para aplica√ß√µes m√≥veis

### Callbacks do Keras
- **EarlyStopping**: Evita overfitting
- **ReduceLROnPlateau**: Ajusta LR automaticamente
- **ModelCheckpoint**: Salva melhor vers√£o

### M√©tricas de Classifica√ß√£o
- **Accuracy**: Taxa de acertos geral
- **Precision**: Acertos entre os preditos
- **Recall**: Acertos entre os verdadeiros
- **F1-Score**: M√©dia harm√¥nica P e R

## üéâ Conclus√£o

A Fase 2 est√° **100% implementada** e pronta para uso. Todos os m√≥dulos, scripts e documenta√ß√£o necess√°rios foram criados seguindo as melhores pr√°ticas de:

- ‚úÖ C√≥digo modular e reutiliz√°vel
- ‚úÖ Documenta√ß√£o completa
- ‚úÖ Configura√ß√µes centralizadas
- ‚úÖ Visualiza√ß√µes autom√°ticas
- ‚úÖ Tratamento de erros
- ‚úÖ Melhores pr√°ticas de ML

**Voc√™ pode come√ßar o treinamento agora mesmo!** üöÄ

---

**Criado em**: 2025-10-09  
**Status**: ‚úÖ PRONTO PARA PRODU√á√ÉO  
**Pr√≥xima Fase**: Fase 3 - Aplica√ß√£o em Tempo Real





