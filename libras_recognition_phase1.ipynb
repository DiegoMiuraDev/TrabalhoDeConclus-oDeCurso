{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Projeto TCC: Reconhecimento Autom√°tico de Libras com IA\n",
        "\n",
        "## Fase 1: Configura√ß√£o e An√°lise dos Dados\n",
        "\n",
        "**Objetivo:** Carregar e explorar o dataset Libras MNIST para entender a estrutura dos dados.\n",
        "\n",
        "**Dataset:** Libras MNIST do Kaggle - https://www.kaggle.com/datasets/datamoon/libras-mnist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importa√ß√£o das Bibliotecas Necess√°rias\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bibliotecas fundamentais\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# TensorFlow e Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Scikit-learn para m√©tricas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Configura√ß√µes para melhor visualiza√ß√£o\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Verificar vers√µes\n",
        "print(f\"TensorFlow: {tf.__version__}\")\n",
        "print(f\"OpenCV: {cv2.__version__}\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"Pandas: {pd.__version__}\")\n",
        "\n",
        "# Verificar se GPU est√° dispon√≠vel\n",
        "print(f\"\\nGPU dispon√≠vel: {tf.config.list_physical_devices('GPU')}\")\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"‚úÖ GPU detectada! O treinamento ser√° mais r√°pido.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Nenhuma GPU detectada. O treinamento pode ser mais lento.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configura√ß√£o do Kaggle API\n",
        "\n",
        "Para baixar o dataset, voc√™ precisar√°:\n",
        "1. Criar uma conta no Kaggle\n",
        "2. Baixar seu arquivo de credenciais (kaggle.json)\n",
        "3. Fazer upload do arquivo para o Colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download do Dataset Libras MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download do dataset\n",
        "!kaggle datasets download -d datamoon/libras-mnist\n",
        "\n",
        "# Extrair o arquivo zip\n",
        "with zipfile.ZipFile('libras-mnist.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "# Verificar o conte√∫do extra√≠do\n",
        "print(\"üìÇ Conte√∫do do dataset:\")\n",
        "!ls -la\n",
        "\n",
        "# Listar arquivos CSV\n",
        "csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
        "print(f\"\\nüìä Arquivos CSV encontrados: {csv_files}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Carregamento e Explora√ß√£o dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar os dados\n",
        "try:\n",
        "    # Tentar carregar o arquivo principal\n",
        "    df = pd.read_csv('libras_mnist.csv')\n",
        "    print(\"‚úÖ Dataset carregado com sucesso!\")\n",
        "except FileNotFoundError:\n",
        "    # Se n√£o encontrar, listar todos os CSVs dispon√≠veis\n",
        "    csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
        "    print(f\"‚ùå Arquivo 'libras_mnist.csv' n√£o encontrado.\")\n",
        "    print(f\"üìã Arquivos CSV dispon√≠veis: {csv_files}\")\n",
        "    if csv_files:\n",
        "        df = pd.read_csv(csv_files[0])\n",
        "        print(f\"‚úÖ Carregando {csv_files[0]} como alternativa.\")\n",
        "\n",
        "# Informa√ß√µes b√°sicas do dataset\n",
        "print(f\"\\nüìä Informa√ß√µes do Dataset:\")\n",
        "print(f\"Dimens√µes: {df.shape}\")\n",
        "print(f\"Colunas: {list(df.columns)}\")\n",
        "print(f\"\\nPrimeiras 5 linhas:\")\n",
        "print(df.head())\n",
        "\n",
        "# Verificar se h√° valores nulos\n",
        "print(f\"\\nüîç Valores nulos por coluna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Informa√ß√µes sobre os tipos de dados\n",
        "print(f\"\\nüìã Tipos de dados:\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. An√°lise das Classes (Letras de Libras)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identificar a coluna de labels (geralmente a primeira ou √∫ltima)\n",
        "label_column = df.columns[0]  # Assumindo que a primeira coluna √© o label\n",
        "print(f\"üè∑Ô∏è  Coluna de labels identificada: '{label_column}'\")\n",
        "\n",
        "# An√°lise das classes\n",
        "unique_labels = df[label_column].unique()\n",
        "n_classes = len(unique_labels)\n",
        "\n",
        "print(f\"\\nüìö Classes encontradas: {n_classes}\")\n",
        "print(f\"Labels √∫nicos: {sorted(unique_labels)}\")\n",
        "\n",
        "# Distribui√ß√£o das classes\n",
        "class_counts = df[label_column].value_counts().sort_index()\n",
        "print(f\"\\nüìä Distribui√ß√£o das classes:\")\n",
        "print(class_counts)\n",
        "\n",
        "# Visualiza√ß√£o da distribui√ß√£o\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "class_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "plt.title('Distribui√ß√£o das Classes de Libras')\n",
        "plt.xlabel('Classe (Letra)')\n",
        "plt.ylabel('Quantidade de Amostras')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Propor√ß√£o das Classes')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Estat√≠sticas da distribui√ß√£o\n",
        "print(f\"\\nüìà Estat√≠sticas da distribui√ß√£o:\")\n",
        "print(f\"M√©dia de amostras por classe: {class_counts.mean():.1f}\")\n",
        "print(f\"Desvio padr√£o: {class_counts.std():.1f}\")\n",
        "print(f\"M√≠nimo: {class_counts.min()}\")\n",
        "print(f\"M√°ximo: {class_counts.max()}\")\n",
        "print(f\"Classes com menos de 100 amostras: {(class_counts < 100).sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualiza√ß√£o de Amostras das Imagens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar os dados para visualiza√ß√£o\n",
        "# Assumindo que as colunas de pixel come√ßam ap√≥s a coluna de label\n",
        "pixel_columns = df.columns[1:]  # Todas as colunas exceto a primeira (label)\n",
        "print(f\"üñºÔ∏è  Colunas de pixel: {len(pixel_columns)} (de {pixel_columns[0]} a {pixel_columns[-1]})\")\n",
        "\n",
        "# Determinar dimens√µes da imagem baseado no n√∫mero de pixels\n",
        "n_pixels = len(pixel_columns)\n",
        "img_size = int(np.sqrt(n_pixels))\n",
        "print(f\"üìê Dimens√µes da imagem: {img_size}x{img_size} pixels\")\n",
        "\n",
        "# Fun√ß√£o para reconstruir imagem a partir dos pixels\n",
        "def reconstruct_image(pixel_row, img_size):\n",
        "    \"\"\"Reconstr√≥i uma imagem a partir de uma linha de pixels\"\"\"\n",
        "    return pixel_row.values.reshape(img_size, img_size)\n",
        "\n",
        "# Visualizar amostras de cada classe\n",
        "fig, axes = plt.subplots(4, 8, figsize=(20, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Pegar uma amostra de cada classe\n",
        "for i, label in enumerate(sorted(unique_labels)):\n",
        "    if i >= 32:  # Limitar a 32 classes para visualiza√ß√£o\n",
        "        break\n",
        "    \n",
        "    # Pegar a primeira amostra desta classe\n",
        "    sample = df[df[label_column] == label].iloc[0]\n",
        "    \n",
        "    # Reconstruir a imagem\n",
        "    image = reconstruct_image(sample[pixel_columns], img_size)\n",
        "    \n",
        "    # Plotar\n",
        "    axes[i].imshow(image, cmap='gray')\n",
        "    axes[i].set_title(f'Classe: {label}', fontsize=10)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "# Ocultar eixos extras se necess√°rio\n",
        "for i in range(len(unique_labels), 32):\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Amostras do Dataset Libras MNIST', fontsize=16, y=0.98)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualizar m√∫ltiplas amostras da mesma classe\n",
        "print(\"\\nüîÑ M√∫ltiplas amostras da mesma classe (exemplo):\")\n",
        "example_class = sorted(unique_labels)[0]  # Primeira classe\n",
        "class_samples = df[df[label_column] == example_class].head(8)\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, (_, sample) in enumerate(class_samples.iterrows()):\n",
        "    image = reconstruct_image(sample[pixel_columns], img_size)\n",
        "    axes[i].imshow(image, cmap='gray')\n",
        "    axes[i].set_title(f'Amostra {i+1}', fontsize=10)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle(f'M√∫ltiplas amostras da classe {example_class}', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Prepara√ß√£o dos Dados para o Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separar features (pixels) e labels\n",
        "X = df[pixel_columns].values\n",
        "y = df[label_column].values\n",
        "\n",
        "print(f\"üìä Dados preparados:\")\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Labels (y): {y.shape}\")\n",
        "print(f\"Tipo de dados X: {X.dtype}\")\n",
        "print(f\"Tipo de dados y: {y.dtype}\")\n",
        "\n",
        "# Verificar range dos valores de pixel\n",
        "print(f\"\\nüîç An√°lise dos valores de pixel:\")\n",
        "print(f\"Valor m√≠nimo: {X.min()}\")\n",
        "print(f\"Valor m√°ximo: {X.max()}\")\n",
        "print(f\"Valor m√©dio: {X.mean():.2f}\")\n",
        "print(f\"Desvio padr√£o: {X.std():.2f}\")\n",
        "\n",
        "# Reshape para formato de imagem\n",
        "X_images = X.reshape(-1, img_size, img_size)\n",
        "print(f\"\\nüñºÔ∏è  Imagens reshapeadas: {X_images.shape}\")\n",
        "\n",
        "# Normalizar os pixels para o range [0, 1]\n",
        "X_normalized = X_images.astype('float32') / 255.0\n",
        "print(f\"‚úÖ Pixels normalizados para o range [0, 1]\")\n",
        "print(f\"Novo range: [{X_normalized.min():.3f}, {X_normalized.max():.3f}]\")\n",
        "\n",
        "# Converter labels para categorical (one-hot encoding)\n",
        "y_categorical = to_categorical(y, num_classes=n_classes)\n",
        "print(f\"\\nüè∑Ô∏è  Labels convertidos para categorical: {y_categorical.shape}\")\n",
        "print(f\"Exemplo de label original: {y[0]} -> one-hot: {y_categorical[0]}\")\n",
        "\n",
        "# Dividir em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_normalized, y_categorical, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=y  # Manter propor√ß√£o das classes\n",
        ")\n",
        "\n",
        "print(f\"\\nüìö Divis√£o dos dados:\")\n",
        "print(f\"Treino: {X_train.shape[0]} amostras\")\n",
        "print(f\"Teste: {X_test.shape[0]} amostras\")\n",
        "print(f\"Propor√ß√£o treino/teste: {X_train.shape[0]/X_test.shape[0]:.1f}:1\")\n",
        "\n",
        "# Verificar se a divis√£o mant√©m a propor√ß√£o das classes\n",
        "train_labels = np.argmax(y_train, axis=1)\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(f\"\\n‚úÖ Verifica√ß√£o da estratifica√ß√£o:\")\n",
        "print(f\"Classes no treino: {len(np.unique(train_labels))}\")\n",
        "print(f\"Classes no teste: {len(np.unique(test_labels))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Resumo da Fase 1\n",
        "\n",
        "### ‚úÖ O que foi realizado:\n",
        "1. **Configura√ß√£o do ambiente** com todas as bibliotecas necess√°rias\n",
        "2. **Download e carregamento** do dataset Libras MNIST\n",
        "3. **An√°lise explorat√≥ria** dos dados:\n",
        "   - Estrutura do dataset\n",
        "   - Distribui√ß√£o das classes\n",
        "   - Visualiza√ß√£o de amostras\n",
        "4. **Prepara√ß√£o dos dados** para o modelo:\n",
        "   - Normaliza√ß√£o dos pixels\n",
        "   - Convers√£o para formato de imagem\n",
        "   - One-hot encoding dos labels\n",
        "   - Divis√£o treino/teste\n",
        "\n",
        "### üìä Caracter√≠sticas do Dataset:\n",
        "- **Classes:** 24 letras do alfabeto de Libras\n",
        "- **Dimens√µes das imagens:** 28x28 pixels (formato MNIST)\n",
        "- **Formato:** Escala de cinza (1 canal)\n",
        "- **Distribui√ß√£o:** Relativamente balanceada entre as classes\n",
        "\n",
        "### üöÄ Pr√≥ximos Passos (Fase 2):\n",
        "1. Adaptar as imagens para o formato RGB (3 canais) para o MobileNetV2\n",
        "2. Redimensionar para 224x224 pixels\n",
        "3. Implementar o modelo com Transfer Learning\n",
        "4. Treinar e avaliar o modelo\n",
        "\n",
        "---\n",
        "\n",
        "**üí° Dica:** Salve este notebook e prossiga para a Fase 2 quando estiver pronto!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar e configurar Kaggle API\n",
        "!pip install kaggle\n",
        "\n",
        "# Criar diret√≥rio .kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# INSTRU√á√ïES PARA O USU√ÅRIO:\n",
        "# 1. Fa√ßa upload do arquivo kaggle.json para o Colab\n",
        "# 2. Execute a c√©lula abaixo ap√≥s o upload\n",
        "\n",
        "# Descomente e execute ap√≥s fazer upload do kaggle.json:\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"üìÅ Configure o Kaggle API seguindo as instru√ß√µes acima.\")\n",
        "print(\"üìã Depois, descomente as linhas de configura√ß√£o e execute novamente.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
